# üå≤ Forest Fire ‚Äî Projeto Paralelo e Distribu√≠do

**EC48A ‚Äî Sistemas Distribu√≠dos (UTFPR-CP) - C81**
<p> Projeto final desenvolvido para a disciplina de Sistemas Distribu√≠dos, aplicando t√©cnicas de programa√ß√£o sequencial, paralela e distribu√≠da para simular o cl√°ssico modelo de propaga√ß√£o de inc√™ndios florestais (Forest Fire Model). </p>

---

## üéØ Objetivo

Implementar e comparar tr√™s vers√µes do modelo de inc√™ndios florestais (Forest Fire):

* Vers√£o Sequencial
* Vers√£o Paralela (Threads Python)
* Vers√£o Distribu√≠da (Sockets TCP)

O objetivo central √© analisar:

* üî• Desempenho
* üî• Speedup
* üî• Escalabilidade
* üî• Custos de comunica√ß√£o
* üî• Limita√ß√µes da paraleliza√ß√£o e distribui√ß√£o

---

## üå± Conceitos Envolvidos

### üìå Modelo Forest Fire (Stanford / Drossel‚ÄìSchwabl)

Um aut√¥mato celular probabil√≠stico onde cada c√©lula pode estar em um de tr√™s estados:

* 0 ‚Äì Vazio
* 1 ‚Äì √Årvore
* 2 ‚Äì Queimando

A evolu√ß√£o segue as regras probabil√≠sticas cl√°ssicas:

1. Uma √°rvore pega fogo se algum vizinho estiver queimando
2. Uma √°rvore pode acender sozinha com probabilidade **f** (raios)
3. Uma c√©lula vazia pode crescer uma √°rvore com probabilidade **p**
4. Uma c√©lula queimando vira vazia

Esse modelo √© amplamente usado para estudar sistemas cr√≠ticos, din√¢mica de propaga√ß√£o e aut√¥matos celulares.

### üìå T√©cnicas Computacionais

* Execu√ß√£o sequencial pura
* Paralelismo com Threads (GIL-bound, mas √∫til para I/O e simula√ß√£o)**
* Dom√≠nio dividido (decomposition)
* Comunica√ß√£o via Sockets TCP em topologia linear
* Sincroniza√ß√£o de fronteiras (ghost rows)
* Medi√ß√£o de tempos com `time.perf_counter`
* Plotagem e an√°lise com matplotlib + CSV

---

# üë• Integrantes e suas contribui√ß√µes (Grupo 2)

* [<img src="https://i.imgur.com/6wtHdzd.png" width="30">](https://github.com/felipebataglini) **Felipe de Oliveira Guimar√£es Bataglini**
  - Implementa√ß√£o vers√£o distribu√≠da
  - Comunica√ß√£o via sockets
  - Testes e valida√ß√£o
  
* [<img src="https://i.imgur.com/fA4JpJg.png" width="30">](https://github.com/JoaoVBLaneiro) **Jo√£o Vitor Briganti Laneiro**
  - Implementa√ß√£o vers√£o paralela com threads
  - Sistema de logging e CSV
  - Documenta√ß√£o t√©cnica
  
* [<img src="https://i.imgur.com/0ldubtT.png" width="30">](https://github.com/Noghiros) **Stefano Calheiros Stringhini**
  - Implementa√ß√£o vers√£o sequencial
  - Desenvolvimento do sistema de benchmark
  - An√°lise de resultados

---

## ‚öôÔ∏è Depend√™ncias

```sh
pip install numpy matplotlib
```

* Python **3.8+**
* `numpy` ‚Äî matrizes e atualiza√ß√£o do aut√¥mato
* `matplotlib` ‚Äî gera√ß√£o de gr√°ficos comparativos
* (`socket`, `threading`, `csv` ‚Üí nativos do Python)

---

## üß™ Metodologia de Testes

Foram executadas baterias de testes variando:

* Tamanho da grade:
  `50√ó50`, `100√ó100`, `200√ó200`, ...
* N√∫mero de itera√ß√µes:
  `10`, `30`, `50`, `100`...
* N√∫mero de threads / processos distribu√≠dos:
  `2`, `4`, `8`...

Cada execu√ß√£o foi repetida de 3 a 5 vezes, com c√°lculo de:

* Tempo m√©dio
* Speedup
* Efici√™ncia
* Tempo gasto em comunica√ß√£o (vers√£o distribu√≠da)

Ferramentas de medi√ß√£o:

* `perf_counter()`
* arquivos `.csv` gerados automaticamente
* `plotar_graficos.py` para gerar gr√°ficos

## üíª Ambiente de Testes

### Hardware
- **CPU**: [Intel Core i3-7100U CPU @ 2.40GHz - 2 N√∫cleos F√≠sicos / 4 Threads L√≥gicas (Virtual Cores)]
- **RAM**: [12,0 GB DDR4]
- **Rede**: [Localhost (127.0.0.1) ‚Äî Custo Zero de Lat√™ncia Real, mas o overhead de serializa√ß√£o/socket √© mensurado.]
- **Sistema**: [Windows 10 Home]

### Software
- **Python**: 3.12.1
- **Bibliotecas**: numpy 2.2.6, matplotlib 3.1.0.7

---

## ‚ñ∂Ô∏è Etapas para Execu√ß√£o

### **1. Vers√£o Sequencial**

```sh
python sequencial/forest_fire_sequencial.py
```

### **2. Vers√£o Paralela com Threads**

```sh
python paralelo/forest_fire_paralelo.py <num_threads>
```

### **3. Vers√£o Distribu√≠da (Local)**

```sh
python run_distributed_local.py <num_procs> <base_port> Nx Ny nsteps p f d0
```

Exemplo real:

```sh
python run_distributed_local.py 4 9000 50 50 30 0.01 0.0001 0.6
```

### **4. Gerar gr√°ficos**

```sh
python plotar_graficos.py
```

---

# üìä Resultados Obtidos

### Tabela Comparativa de Tempos (segundos)

| Tamanho    | Sequencial | 2 Threads | 4 Threads | 2 Workers | 4 Workers |
|------------|------------|-----------|-----------|-----------|-----------|
| 256√ó256    | 0.96s      | 43.96s    | 44.37s    | 29.33s    | 24.07s    |
| 512√ó512    | 3.26s      | 183.19s   | 182.33s   | 112.83s   | 90.23s    |
| 1024√ó1024  | 9.30s      | 728.02s   | 771.74s   | 560.37s   | 357.11s   |

### Gr√°ficos de Desempenho
<img width="800" height="500" alt="Gr√°fico Comparativo" src="https://github.com/user-attachments/assets/8b725016-9a0e-4603-ab0c-d92cd23b870e" />

### An√°lise de Speedup

| Configura√ß√£o  | 256√ó256 | 512√ó512 | 1024√ó1024 | Efici√™ncia |
|---------------|---------|---------|-----------|------------|
| 2 Threads     | 0.02x   | 0.02x   | 0.01x     | 1.0%       |
| 4 Threads     | 0.02x   | 0.02x   | 0.01x     | 0.5%       |
| 2 Workers     | 0.03x   | 0.03x   | 0.02x     | 1.5%       |
| 4 Workers     | 0.04x   | 0.04x   | 0.03x     | 0.8%       |

## ‚ö†Ô∏è Limita√ß√µes Identificadas

Os resultados mostram que as vers√µes paralela e distribu√≠da apresentaram desempenho inferior √† vers√£o sequencial, indicando **overhead excessivo** nas implementa√ß√µes atuais. 
Isso se deve principalmente √† sincroniza√ß√£o frequente e custos de comunica√ß√£o que superam os ganhos da paraleliza√ß√£o, conforme detalhado abaixo:

* **Paralela (Threads): Slowdown Causado pelo GIL**
  A simula√ß√£o √© classificada como CPU-bound (limitada pela capacidade de c√°lculo da CPU). O ganho de desempenho foi nulo devido ao Python Global Interpreter Lock (GIL).
  - **Problema:** O GIL garante que apenas uma thread execute c√≥digo Python por vez, impedindo o paralelismo real em CPUs multi-core. 
  - **Consequ√™ncia:** A implementa√ß√£o com threading incorre no alto custo de gerenciamento e sincroniza√ß√£o de 4 threads, mas sem o benef√≠cio da execu√ß√£o simult√¢nea, resultando em um enorme slowdown.
  - **Resultado:** O tempo foi de 771.74s (4 Threads) contra a baseline sequencial de 9.30s.

* **Distribu√≠da (Sockets): Penalidade do Overhead de Comunica√ß√£o**
  - **Alto Custo para Granularidade Fina:** A troca de Ghost Rows em Sockets TCP a cada um dos 200 passos da simula√ß√£o exige repetida serializa√ß√£o (numpy para bytes) e desserializa√ß√£o
  - **Sincroniza√ß√£o Excessiva:** Sincroniza√ß√£o total e frequente entre todos os workers
  - **Resultado:** Overhead de comunica√ß√£o superior ao tempo de processamento sequencial

## üöÄ Melhorias Propostas

üîß **Para Vers√£o Paralela**:
- Usar o m√≥dulo _multiprocessing_ (em vez de _threading_) para criar processos separados, cada um com sua pr√≥pria inst√¢ncia do interpretador Python, permitindo a execu√ß√£o simult√¢nea em m√∫ltiplos n√∫cleos f√≠sicos.

üîß **Para Vers√£o Distribu√≠da**:
- Usar bibliotecas otimizadas como MPI (Message Passing Interface) em vez de Sockets puros. MPI √© projetado para transfer√™ncia de grandes volumes de dados de forma eficiente em computa√ß√£o paralela e distribu√≠da.
- Buscar uma arquitetura de granularidade mais grossa (se o problema permitir), reduzindo a frequ√™ncia de comunica√ß√£o.

---

# üìö Refer√™ncias

### üìÑ Modelo Forest Fire

* **Drossel, B. & Schwabl, F.** (1992). *Self-organized critical forest-fire model*. Physical Review Letters.
* **Stanford CS** ‚Äì Cellular Automata: Forest Fire Model (modelo cl√°ssico utilizado amplamente em cursos e implementa√ß√µes)
* **Karafyllidis & Thanailakis** (1997). *A cellular automata wildfire spread model*.

### üìÑ Aut√¥matos e din√¢mica do fogo

* **Schenk et al.** (2001). *Forest fire models on large scales*. arXiv.
* **Ghosh, R.** (2024). *Probabilistic Cellular Automata Fire Spread Model*. [arXiv](https://arxiv.org/pdf/2403.08817).

### üí¨ Cr√©ditos de desenvolvimento

* Google, StackOverflow, Documenta√ß√£o oficial de Python
* Intera√ß√£o com ChatGPT, DeepSeek e Gemini durante desenvolvimento
* E como sempre: f√©, caf√©, for√ßa de vontade e todas as ferramentas ao nosso alcance
